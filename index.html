<html><head><meta http-equiv="Content-Type" content="text/html; charset=GBK">
<meta name="keywords" content="Chang Tang, Tang Chang, machine learning, CUG, China University of Geosciences"> 
<meta name="description" content="Chang Tang&#39;s home page">
<link href="main_style.css" media="all" rel="stylesheet">
<title>Chang Tang - Homepage</title>
</head>

<body>
<div id="navbar" align=right><a href="/">HOME</a>  
	<a href="/publications.html">PUBLICATIONS</a>  
	<a href="/teaching.html">TEACHING</a>  
	<a href="/contact.html">CONTACT</a>  
	<a href="/misc.html">MISC</a>  
	<a href="/personal.html">PERSONAL</a></div>
<hr>
<br><br>
<table id="tbInformation" width="100%">
	<tbody>
	<tr>
		<td width="500">
		<h1>CHANG TANG <img src="/indexfiles/tangchang_chinese_s.jpg"></h1>
		</td>
		<td rowspan="3" align="center">
		<img src="/indexfiles/tangchang.jpg" border="0" width="300" height="200">
		</td>
	</tr>


	<tr>
		<td>	
        <h3>Associate Professor</br> 
		School of Computer Science</br> 
		China University of Geosciences (CUG)</h3>
<br>
		<strong>Email:</strong> happytangchang@gmail.com; &nbsp;&nbsp; tangchang@cug.edu.cn</br>
		<strong>QQ:</strong> 515667845</br>
		<strong>WeChat:</strong> TangChang87
		</td>
	</tr>

</tbody>
</table>
<table width="100%">
	<tbody>
    <tr>
		<td><font color="#FF0000"><strong>I am looking for new MS/BS students to join my research project working on machine learning and computer vision. If you have a solid mathematical & English background and happen to be interested in my research, please contact me!</strong></font>
		</td>
	</tr>
	</tbody>
</table>

<hr>
<h3>ABOUT ME:</h3>
<p>My research interests lie in the areas of computer vision and machine learning. I am recently interested in building machine larning models for solving computer vision problems. </p>
<hr>
<h3>RECENT NEWS:</h3>
<p>
<ol id="NewsOL">
    <li>2017-03-03: One co-authored paper was accepted by IEEE CVPR 2017.</li>
</ol> 
</p>
<hr>
<h3>RECENT PUBLICATIONS:</h3>
<p><a href="https://scholar.google.com/citations?user=quDLqhwAAAAJ&hl=en">Google Scholar</a></p>
<table id="tbPublications" width="100%">
    <tbody>
	<tr><td><strong>2017</strong></td></tr>
	<tr><td><hr></td><td><hr></td></tr>
	<tr>
    	<td width="306"> <img src="/pubfiles/sceneflowAction.jpg" width="290px"></td>
		<td>
		Pichao Wang, Wanqing Li, Zhimin Gao, Yuyao Zhang, <b>Chang Tang</b>, Philip Ogunbona, "Scene Flow to Action Map: A New Representation for RGB-D based Action Recognition with Convolutional Neural Networks", IEEE Conference on Computer Vision and Pattern Recognition(<i><b> CVPR</b></i>)(Accepted), 2017.<p>[Code]</P>
		</td>	
	</tr>
	<tr>
    	<td width="306"> <img src="/pubfiles/WLRR.jpg" width="290px"></td>
		<td>
		<b>Chang Tang</b>, Pichao Wang, Changqing Zhang, Wanqing Li, "Salient Object Detection via Weighted Low Rank Matrix Recovery", IEEE Signal Processing Letters (<i><b>IEEE SPL</b></i>)24(4), 490-494, 2017.<p>[<a href="/codes/WLRRSalDemo.zip">Code</a>]</P>
		</td>	
	</tr>
	<tr>
    	<td width="306"> <img src="/pubfiles/smooth.png" width="290px">		</td>		
	    <td>
		<b>Chang Tang</b>, Chunping Hou, Yonghong Hou, Pichao Wang, Wanqing Li, "An Effective Edge-preserving Smoothing Method for Image Manipulation", Elsevier Digital Signal Processing (<i><b>Elsevier DSP</b></i>)10, 10-24, 2017.<p>[<a href="/codes/SmoothingDemo.zip">Code</a>]</P>
		</td>	
	</tr>
	<tr>
    	<td width="306"> <img src="/pubfiles/OCTDespeckle.jpg" width="290px">		</td>		
	    <td>
		<b>Chang Tang</b>, Lijuan Cao, Jiajia Chen, Xiao Zheng, "Speckle noise reduction for optical coherence tomography images via non-local weighted group low-rank representation", Laser Physics Letters, 14(5), 2017.<p>[<a href="/codes/WGLRRDemo.zip">Code</a>]</P>
		</td>	
	</tr>
	<tr><td><strong>2016</strong></td></tr>
	<tr><td><hr></td><td><hr></td></tr>		
	<tr>
    	<td width="306"> <img src="/pubfiles/BlurDetection.jpg" width="290px">		</td>		
	    <td>
		<b>Chang Tang</b>, Jin Wu, Yonghong Hou, Pichao Wang, Wanqing Li, "A spectral and spatial approach of coarse-to-fine blurred image region detection", IEEE Signal Processing Letters (<i><b>IEEE SPL</b></i>), 23(11), 1652-1656, 2016.<p>[<a href="/codes/BlurDemoCode.zip">Code</a>]</P>	
		</td>	
	</tr>	
	<tr>
    	<td width="306"> <img src="/pubfiles/RGBDSurvey.jpg" width="290px">		</td>		
	    <td>
		Pichao Wang, Wanqing Li, Song Liu, Zhimin Gao, <b>Chang Tang</b>, Philip Ogunbona, "Large-scale Isolated Gesture Recognition Using Convolutional Neural Networks", in ChaLearn Looking at People (LAP) Challenge, ICPR2016, 2016. (rank the 2nd place)	
		</td>	
	</tr>	
	<tr>
    	<td width="306"> <img src="/pubfiles/RGBDSurvey.jpg" width="290px">		</td>		
	    <td>
		Jing Zhang, Wanqing Li, Pichao Wang, Philip Ogunbona, Song Liu and, <b>Chang Tang</b>, "A Large Scale RGB-D Dataset for Action Recognition", International Workshop on Understanding Human Activities through 3D Sensors (UHA3DS workshop@ICPR2016), 2016. 	
		</td>	
	</tr>	
	<tr>
    	<td width="306"><img src="/pubfiles/RGBDSurvey.jpg" width="290px">		</td>		
	    <td>
		Jing Zhang, Wanqing Li, Philip Ogunbona, Pichao Wang, <b>Chang Tang</b>, "RGB-D-based Action Recognition Datasets: A Survey", Pattern Recognition, 60(1), 86-105, 2016.
		</td>	
	</tr>		
    <tr><td><strong>2015</strong></td></tr>
	<tr><td><hr></td><td><hr></td></tr>
	<tr>
		<td width="306">
		<img src="/pubfiles/CNNActionRocognition.png" width="290">			
		</td>
		<td>
		Pichao Wang, Wanqing Li, Zhimin Gao, <b>Chang Tang</b>, Jing Zhang, Philip O. Ogunbona. , "ConvNets-Based Action Recognition from Depth Maps through Virtual Cameras and Pseudocoloring", ACM international conference on Multimedia(ACMM), 1119-1122, 2015. <p>[<a href="https://sites.google.com/site/pichaossites/resources/ACM.zip?attredirects=0&d=1">Code</a>]</P>.
		</td>
	</tr>
	<tr>
		<td width="306">
		<img src="/pubfiles/BeyondCov.png" width="290">			
		</td>
		<td>
		Lei Wang, Jianjia Zhang, Luping Zhou, <b>Chang Tang</b>, Wanqing Li, "Beyond Covariance: Feature Representation with Nonlinear Kernel matrices", IEEE International Conference on Computer Vision (ICCV), 4570-4578, 2015. <p>[<a href="http://www.uow.edu.au/~leiw/share_files/Kernel_representation_Code_for_release.zip">Code</a>]</P>	
		</td>
	</tr>
	<tr>
		<td width="306">
		<img src="/pubfiles/CNNActionRocognition.png" width="290">			
		</td>
		<td>
		Wang Pichao, Li Wanqing, Gao Zhimin, Zhang Jing, <b>Chang Tang</b>, Ogunbona Philip, "Action Recognition From Depth Maps Using Deep Convolutional Neural Networks", IEEE Transactions on Human-machine Systems, pp(99), 1-12, 2015. <p>[<a href="https://sites.google.com/site/pichaossites/resources/ACM.zip?attredirects=0&d=1">Code</a>]</P>.
		</td>
	</tr>
	<tr>
		<td width="306">
		<img src="/pubfiles/SaliencyFrameWork.png" width="290">			
		</td>
		<td>
		<b>Chang Tang</b>, Chunping Hou, Pichao Wang, Zhanjie Song, "Salient object detection using color spatial distribution and minimum spanning tree weight", Multimedia Tools and Applications, Accepted, 75(12), 6963-6978, 2015.
		</td>
	</tr>
	<tr><td><strong>2014</strong></td></tr>
	<tr><td><hr></td><td><hr></td></tr>
	<tr>
		<td width="306">
		<img src="/pubfiles/DepthFromDefocus.png" width="290">			
		</td>
		<td>
		<b>Chang Tang</b>, Chunping Hou, and Zhanjie Song, "Depth recovery and refinement from a single image using defocus cues", Journal of Modern Optics, 62(3), 204-211, 2014. <p>[<a href="/codes/OLDefocus.rar">Code</a>]</p>
		</td>
	</tr>
    <tr><td><strong>2013</strong></td></tr>
	<tr><td><hr></td><td><hr></td></tr>
	<tr>
		<td width="306">
		<img border="0" src="/pubfiles/defocus.png" width="290">
		</td>
		<td>
		<b>Chang Tang</b>, Chunping Hou, and Zhanjie Song, "Defocus map estimation from a single image via spectrum contrast", Optics Letters, 38(10), 1706-1708, 2013. <p>[<a href="/codes/OLDefocus.rar">Code</a>]</p>
		</td>
	</tr>	
</tbody></table>
<br>
<hr>
<h3>RESEARCH:</h3>
<!--<p>My research interests lie in the areas of computer vision and computational photography. I am pretty much interested in building practical vision systems. Most of my research
work has software and source code publicly available. My representative work includes optical flow (MDP-Flow2), motion deblurring (Robust Motion Deblurring), image/video representation (L0 Smoothing). I am recently interested in the combination of deep neural network and conventional generative vision
models. </p>
<hr>
<h3>HONORS &amp; AWARDS:</h3>
<table id="tbHonors" border="0" width="100%">
	<tbody><tr>
		<td width="55%">Best Reviewer, ICCV 2015<p> Best Reviewer, ACCV 2012</p>
		<p>Best Paper Award, NPAR 2012</p>
		<p>Best Teaching Assistant Certificate of Merit Award, 2009-2010 </p>
		<p>Booz &amp; Company Social Venture Challenge Finalist (team leader), 2009</p>
		<p>Microsoft Research Asia Fellowship Award, 2008</p>
		<p>Award for Exemption of National Graduate Entry Examinations</p>
<!-- 		<p>Oversea Research Intern Program of SJTU, 2006</p>
		<p>Award for Exemption of National Graduate Entry Examinations,2004</p>
		<p>Excellent Scholarship of SJTU (top 10% in Dept.of CSE), 2000-2004</p>
		<p>Exceptional Student of SJTU (top 10% in Dept. of CSE), 2001, 2003</p></td> 
		<td width="418"><a href="http://lxu.me/index_files/booz.jpg">
		<img src="/pubfiles/index_011.jpg" border="0" height="150" width="215"></a>
		<a href="http://www.cse.cuhk.edu.hk/v7/en/about/achieve/22.html">
		<img src="/pubfiles/index_004.jpg" border="0" height="150" width="215"></a>
		</td>
	</tr>
</tbody></table>
<hr>
<!--<h3>RESEARCH EXPERIENCES:</h3>
<table id="tbExp" border="0" width="100%">
	<tbody><tr>
		<td>
		2013.3 Microsoft Research New England (Boston)
		<p>Work with <a href="http://people.csail.mit.edu/celiu/">
		Ce Liu </a></p>
		<br>
		2008.6~2008.9 Microsoft Research Asia (Beijing)<p><em>Visual 
		Computing</em></p>
		<p>Work with <a href="http://research.microsoft.com/users/yasumat/">
		Yasuyuki Matsushita </a></p>
		<br>
		<p>2006.6~2006.10 OMRON Keihanna Innovation Centre (Kyoto, Japan)</p>
		<p><em>Sensing &amp; Control Technology Laboratory/OKAO Vision</em></p>
		<p>Work with
		<a href="http://scholar.google.com/citations?user=hkguTPgAAAAJ&amp;hl=en">
		Takayoshi Yamashita</a>,
		<a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lao:Shihong.html">
		Shihong Lao</a></p>
		<br>
		<p>2004.10~2006.4 Motorola China Research Centre (Shanghai)</p>
		<p><em>Pattern Recognition Group</em></p>
		<p>Work with Qingshan Chen</p></td>
	</tr>
</tbody>
</table>
<p></p>
<hr>
-->
, , ,
<h3>PROFESSIONAL ACTIVITIES:</h3>
<p><em>Journal Reviewer</em></p>
<table>
	<tbody>
	<tr>
		<td>Optics Letters (OL)
		</td>
	</tr>
	<tr>
		<td>IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)</td>
	</tr>
	<tr>
		<td>IEEE Signal Processing Letters(SPL)</td>
	</tr>
	<tr>
		<td>Multimedia Tools and Applications(MTAP)</td>
	</tr>
	<tr>
		<td>Biomedical Optics Express(BOE)</td>
	</tr>
</tbody></table>
<!--
<p><em>Conference Reviewer/External Reviewer</em></p>
<table>
	<tbody><tr>
		<td>CVPR 2010-2015, ECCV 2010-2014
		</td>
	</tr>
	<tr>
		<td>ICCV 2011-2015, Best Reviewer, ICCV 2015 
		</td>
	</tr>
	<tr>
		<td>Program Committee: CVPR 2013, ACCV 2012, 2014, Best Reviewer, ACCV 2014, Industry Co-Chair ACCV 2016
		</td>
	</tr>
	<tr>
		<td>SIGGRAPH ASIA 2011-2015; SIGGRAPH 2012-2015
		</td>
	</tr>
</tbody>
</table>
-->
<p></p>
<hr>
<br>


</body></html>
